"""
Neo4j å¯¼å…¥å·¥å…· (æœ€ç»ˆä¿®å¤ç‰ˆ)
ä¿®å¤äº† ID ç±»å‹ä¸åŒ¹é…çš„é—®é¢˜ï¼šä»åŒ¹é… UUID æ”¹ä¸ºåŒ¹é… Name
"""

import json
import os
from neo4j import GraphDatabase
from typing import List, Dict, Any
import time


class Neo4jImporter:
    """Neo4j æ•°æ®å¯¼å…¥å™¨"""

    def __init__(self, uri: str, user: str, password: str):
        """
        åˆå§‹åŒ– Neo4j è¿æ¥

        Args:
            uri: Neo4j è¿æ¥åœ°å€ (ä¾‹å¦‚: bolt://localhost:7687)
            user: ç”¨æˆ·å
            password: å¯†ç 
        """
        self.uri = uri
        self.user = user
        self.driver = None

        try:
            self.driver = GraphDatabase.driver(uri, auth=(user, password))
            # æµ‹è¯•è¿æ¥
            with self.driver.session() as session:
                result = session.run("RETURN 1 as test")
                result.single()
            print(f"âœ“ æˆåŠŸè¿æ¥åˆ° Neo4j: {uri}")
        except Exception as e:
            print(f"âœ— è¿æ¥ Neo4j å¤±è´¥: {e}")
            raise

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.driver:
            self.driver.close()
            print("âœ“ æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def load_json_data(self, json_file: str) -> Dict[str, Any]:
        """
        ä» JSON æ–‡ä»¶åŠ è½½æ•°æ®

        Args:
            json_file: JSON æ–‡ä»¶è·¯å¾„

        Returns:
            åŒ…å« entities å’Œ triples çš„å­—å…¸
        """
        if not os.path.exists(json_file):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {json_file}")

        print(f"\nåŠ è½½æ•°æ®æ–‡ä»¶: {json_file}")

        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        entities = data.get('entities', {})
        triples = data.get('triples', [])
        metadata = data.get('metadata', {})

        print(f"âœ“ åŠ è½½ {len(entities)} ä¸ªå®ä½“")
        print(f"âœ“ åŠ è½½ {len(triples)} ä¸ªä¸‰å…ƒç»„")

        if metadata:
            stats = metadata.get('statistics', {})
            print(f"\næ•°æ®ç»Ÿè®¡:")
            print(f"  å®ä½“æ€»æ•°: {stats.get('total_entities', 0)}")
            print(f"  ä¸‰å…ƒç»„æ€»æ•°: {stats.get('total_triples', 0)}")

        return {
            'entities': entities,
            'triples': triples,
            'metadata': metadata
        }

    def clear_database(self, confirm: bool = True):
        """
        æ¸…ç©ºæ•°æ®åº“ï¼ˆå±é™©æ“ä½œï¼ï¼‰

        Args:
            confirm: å¿…é¡»è®¾ç½®ä¸º True æ‰èƒ½æ‰§è¡Œ
        """
        if not confirm:
            print("âš  æ¸…ç©ºæ•°æ®åº“éœ€è¦ç¡®è®¤ï¼Œè¯·è®¾ç½® confirm=True")
            return

        print("\nâš  è­¦å‘Š: å³å°†æ¸…ç©ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰æ•°æ®ï¼")
        user_input = input("ç¡®è®¤è¦ç»§ç»­å—ï¼Ÿ (è¾“å…¥ 'YES' ç¡®è®¤): ")

        if user_input != "YES":
            print("âœ“ æ“ä½œå·²å–æ¶ˆ")
            return

        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
            print("âœ“ æ•°æ®åº“å·²æ¸…ç©º")

    def create_constraints_and_indexes(self):
        """åˆ›å»ºçº¦æŸå’Œç´¢å¼•ä»¥æé«˜æ€§èƒ½"""
        print("\nåˆ›å»ºçº¦æŸå’Œç´¢å¼•...")

        with self.driver.session() as session:
            # ä¸ºå®ä½“IDåˆ›å»ºå”¯ä¸€çº¦æŸ
            try:
                session.run("""
                    CREATE CONSTRAINT entity_id IF NOT EXISTS
                    FOR (e:Entity) REQUIRE e.id IS UNIQUE
                """)
                print("âœ“ åˆ›å»ºå®ä½“IDå”¯ä¸€çº¦æŸ")
            except Exception as e:
                print(f"âš  åˆ›å»ºçº¦æŸå¤±è´¥ (å¯èƒ½å·²å­˜åœ¨): {e}")

            # ä¸ºå®ä½“åç§°åˆ›å»ºç´¢å¼• (å…³é”®ï¼šæé«˜æŒ‰åç§°æŸ¥æ‰¾çš„é€Ÿåº¦)
            try:
                session.run("""
                    CREATE INDEX entity_name IF NOT EXISTS
                    FOR (e:Entity) ON (e.name)
                """)
                print("âœ“ åˆ›å»ºå®ä½“åç§°ç´¢å¼•")
            except Exception as e:
                print(f"âš  åˆ›å»ºç´¢å¼•å¤±è´¥ (å¯èƒ½å·²å­˜åœ¨): {e}")

            # ä¸ºå®ä½“ç±»å‹åˆ›å»ºç´¢å¼•
            try:
                session.run("""
                    CREATE INDEX entity_type IF NOT EXISTS
                    FOR (e:Entity) ON (e.type)
                """)
                print("âœ“ åˆ›å»ºå®ä½“ç±»å‹ç´¢å¼•")
            except Exception as e:
                print(f"âš  åˆ›å»ºç´¢å¼•å¤±è´¥ (å¯èƒ½å·²å­˜åœ¨): {e}")

    def import_entities(self, entities: Dict[str, Dict[str, Any]], batch_size: int = 1000):
        """
        æ‰¹é‡å¯¼å…¥å®ä½“
        """
        print(f"\nå¯¼å…¥å®ä½“ (æ‰¹å¤§å°: {batch_size})...")

        # è½¬æ¢å­—å…¸ä¸ºåˆ—è¡¨
        entities_list = []
        for entity_id, entity_data in entities.items():
            # ç¡®ä¿ id å­—æ®µå­˜åœ¨
            entity_data['id'] = entity_id
            entities_list.append(entity_data)

        total_batches = (len(entities_list) + batch_size - 1) // batch_size

        start_time = time.time()

        with self.driver.session() as session:
            for i in range(0, len(entities_list), batch_size):
                batch = entities_list[i:i+batch_size]
                batch_num = i // batch_size + 1

                session.run("""
                    UNWIND $entities AS entity
                    MERGE (e:Entity {id: entity.id})
                    SET e.name = entity.name,
                        e.type = entity.type,
                        e.description = entity.description,
                        e.degree = entity.degree,
                        e.community_ids = entity.community_ids,
                        e.text_unit_ids = entity.text_unit_ids
                """, entities=batch)

                print(f"  æ‰¹æ¬¡ {batch_num}/{total_batches} å®Œæˆ ({len(batch)} ä¸ªå®ä½“)")

        elapsed_time = time.time() - start_time
        print(f"âœ“ å¯¼å…¥ {len(entities_list)} ä¸ªå®ä½“å®Œæˆ (è€—æ—¶: {elapsed_time:.2f}ç§’)")

    def import_relationships_without_apoc(self, triples: List[Dict[str, Any]], batch_size: int = 1000):
        """
        ä¸ä½¿ç”¨ APOC æ’ä»¶å¯¼å…¥å…³ç³»
        ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šä½¿ç”¨ name å­—æ®µåŒ¹é…èŠ‚ç‚¹ï¼Œè€Œä¸æ˜¯ id
        """
        print(f"\nå¯¼å…¥å…³ç³» (æ‰¹å¤§å°: {batch_size})...")

        if not triples:
            print("âš  è­¦å‘Š: ä¸‰å…ƒç»„åˆ—è¡¨ä¸ºç©ºï¼")
            return

        # ========== 1. æ™ºèƒ½æ£€æµ‹å­—æ®µå ==========
        sample = triples[0]
        print(f"\nğŸ“‹ æ£€æµ‹ä¸‰å…ƒç»„æ•°æ®ç»“æ„...")
        print(f"   åŸå§‹æ•°æ®é”®: {list(sample.keys())}")

        subject_key = None
        object_key = None

        possible_subject_keys = ['subject_id', 'subject', 'source', 'head']
        possible_object_keys = ['object_id', 'object', 'target', 'tail']

        for key in possible_subject_keys:
            if key in sample:
                subject_key = key
                break

        for key in possible_object_keys:
            if key in sample:
                object_key = key
                break

        if not subject_key or not object_key:
            print(f"âœ— é”™è¯¯: æ— æ³•è¯†åˆ«ä¸‰å…ƒç»„ä¸­çš„IDå­—æ®µåï¼")
            return

        print(f"âœ“ è‡ªåŠ¨åŒ¹é…å­—æ®µ -> Subject: '{subject_key}', Object: '{object_key}'")
        print(f"   æ ·æœ¬æ•°æ®: {sample.get(subject_key)} --[{sample.get('predicate')}]--> {sample.get(object_key)}")

        # ========== 2. å…³é”®éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥æŒ‰åç§°åŒ¹é… ==========
        # å¦‚æœ subject_id çœ‹èµ·æ¥åƒ UUIDï¼Œå°±ç”¨ id åŒ¹é…ï¼›å¦åˆ™ç”¨ name åŒ¹é…
        sample_id_val = str(sample[subject_key])
        # ç®€å•çš„ UUID å¯å‘å¼æ£€æŸ¥ï¼šé•¿åº¦å¤§äº20ä¸”åŒ…å«è¿å­—ç¬¦ï¼Œæˆ–è€…çœ‹èµ·æ¥åƒå“ˆå¸Œ
        is_uuid_like = ('-' in sample_id_val and len(sample_id_val) > 20) or len(sample_id_val) == 32

        if is_uuid_like:
            print(f"   ğŸ” æ£€æµ‹åˆ° ID æ ¼å¼ç±»ä¼¼ UUIDï¼Œå°†ä½¿ç”¨ ID åŒ¹é…èŠ‚ç‚¹")
            match_field = "id"
        else:
            print(f"   ğŸ” æ£€æµ‹åˆ° ID ä¸ºæ–‡æœ¬åç§°ï¼Œå°†ä½¿ç”¨ NAME åŒ¹é…èŠ‚ç‚¹ (ä¿®å¤æ–¹æ¡ˆ)")
            match_field = "name"

        # ========== 3. æ•°æ®æ ‡å‡†åŒ–ä¸åˆ†ç»„ ==========
        relations_by_type = {}

        for triple in triples:
            original_predicate = triple.get('predicate', 'RELATED_TO')
            rel_type = self._normalize_relationship_type(original_predicate)

            if rel_type not in relations_by_type:
                relations_by_type[rel_type] = []

            std_triple = {
                'subject_val': triple[subject_key], # ä½¿ç”¨é€šç”¨é”®å
                'object_val': triple[object_key],
                'weight': triple.get('weight', 0.0),
                'description': triple.get('description', ''),
                'source_degree': triple.get('source_degree', 0),
                'target_degree': triple.get('target_degree', 0),
                'rank': triple.get('rank', 0),
                'original_predicate': original_predicate
            }
            relations_by_type[rel_type].append(std_triple)

        print(f"  å‘ç° {len(relations_by_type)} ç§å…³ç³»ç±»å‹")

        # ========== 4. éªŒè¯èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨ (ä½¿ç”¨ç¡®å®šçš„å­—æ®µ) ==========
        sample_rel_type = list(relations_by_type.keys())[0]
        sample_rel = relations_by_type[sample_rel_type][0]

        sample_sub_val = sample_rel['subject_val']
        sample_obj_val = sample_rel['object_val']

        print(f"\nğŸ” éªŒè¯æ ·æœ¬èŠ‚ç‚¹ (ä½¿ç”¨ {match_field})...")
        with self.driver.session() as session:
            # æ„å»ºæŸ¥è¯¢
            query = f"MATCH (n:Entity) WHERE n.{match_field} = $val RETURN count(n) as c"

            res = session.run(query, val=sample_sub_val)
            sub_count = res.single()['c']

            res = session.run(query, val=sample_obj_val)
            obj_count = res.single()['c']

            if sub_count == 0:
                print(f"   âš  è­¦å‘Š: æºèŠ‚ç‚¹ '{sample_sub_val}' åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ï¼")
            if obj_count == 0:
                print(f"   âš  è­¦å‘Š: ç›®æ ‡èŠ‚ç‚¹ '{sample_obj_val}' åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ï¼")

            if sub_count > 0 and obj_count > 0:
                print(f"   âœ“ æ ·æœ¬èŠ‚ç‚¹éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹å¯¼å…¥")

        # ========== 5. æ‰¹é‡å¯¼å…¥ ==========
        start_time = time.time()
        total_imported = 0

        for rel_type, rel_triples in relations_by_type.items():
            print(f"\n  æ­£åœ¨å¤„ç†å…³ç³»ç±»å‹: {rel_type} ({len(rel_triples)} æ¡)")

            total_batches = (len(rel_triples) + batch_size - 1) // batch_size

            with self.driver.session() as session:
                for i in range(0, len(rel_triples), batch_size):
                    batch = rel_triples[i:i+batch_size]
                    batch_num = i // batch_size + 1

                    try:
                        # ä½¿ç”¨åŠ¨æ€æ„å»ºçš„ Cypherï¼Œæ³¨æ„ä½¿ç”¨ {match_field}
                        # å…³é”®ç‚¹ï¼šn.{match_field} = triple.subject_val
                        query = f"""
                            UNWIND $triples AS triple
                            MATCH (source:Entity)
                            WHERE source.{match_field} = triple.subject_val
                            MATCH (target:Entity)
                            WHERE target.{match_field} = triple.object_val
                            MERGE (source)-[r:{rel_type}]->(target)
                            SET r.weight = triple.weight,
                                r.description = triple.description,
                                r.original_predicate = triple.original_predicate,
                                r.source_degree = triple.source_degree,
                                r.target_degree = triple.target_degree,
                                r.rank = triple.rank
                        """

                        result = session.run(query, triples=batch)
                        summary = result.consume()

                        count = summary.counters.relationships_created
                        total_imported += count

                        if count > 0:
                            print(f"    æ‰¹æ¬¡ {batch_num}/{total_batches}: åˆ›å»ºäº† {count} æ¡å…³ç³»")
                        else:
                            print(f"    æ‰¹æ¬¡ {batch_num}/{total_batches}: è·³è¿‡ (æœªæ‰¾åˆ°èŠ‚ç‚¹)")

                    except Exception as e:
                        print(f"    âœ— æ‰¹æ¬¡ {batch_num}/{total_batches} å¤±è´¥: {e}")

        elapsed_time = time.time() - start_time
        print(f"\nâœ“ å…³ç³»å¯¼å…¥å®Œæˆã€‚æ€»è®¡åˆ›å»º: {total_imported} æ¡ (è€—æ—¶: {elapsed_time:.2f}ç§’)")

    def _normalize_relationship_type(self, predicate: str) -> str:
        """æ ‡å‡†åŒ–å…³ç³»ç±»å‹åç§°"""
        if not predicate or not predicate.strip():
            return 'RELATED_TO'

        normalized = predicate.strip().replace(' ', '_')
        normalized = ''.join(c if c.isalnum() or c == '_' else '_' for c in normalized)
        normalized = normalized.upper()
        while '__' in normalized:
            normalized = normalized.replace('__', '_')
        normalized = normalized.strip('_')

        if not normalized or normalized.replace('_', '') == '':
            return 'RELATED_TO'

        if normalized[0].isdigit():
            normalized = 'REL_' + normalized

        return normalized

    def verify_import(self):
        """éªŒè¯å¯¼å…¥ç»“æœ"""
        print("\néªŒè¯å¯¼å…¥ç»“æœ...")

        with self.driver.session() as session:
            # ç»Ÿè®¡èŠ‚ç‚¹æ•°
            result = session.run("MATCH (n:Entity) RETURN count(n) as count")
            node_count = result.single()['count']

            # ç»Ÿè®¡å…³ç³»æ•°
            result = session.run("MATCH ()-[r]->() RETURN count(r) as count")
            rel_count = result.single()['count']

            # ç»Ÿè®¡å…³ç³»ç±»å‹
            result = session.run("""
                MATCH ()-[r]->()
                RETURN type(r) as rel_type, count(r) as count
                ORDER BY count DESC
                LIMIT 10
            """)
            rel_types = list(result)

            print("\n" + "="*60)
            print("å¯¼å…¥éªŒè¯ç»“æœ")
            print("="*60)
            print(f"èŠ‚ç‚¹æ€»æ•°: {node_count}")
            print(f"å…³ç³»æ€»æ•°: {rel_count}")

            print(f"\nå…³ç³»ç±»å‹åˆ†å¸ƒ (Top 10):")
            for record in rel_types:
                print(f"  {record['rel_type']}: {record['count']}")

            # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
            print(f"\nç¤ºä¾‹æ•°æ® (éšæœº5æ¡):")
            result = session.run("""
                MATCH (n:Entity)-[r]->(m:Entity)
                RETURN n.name as source, type(r) as relationship, 
                       m.name as target, r.weight as weight
                ORDER BY rand()
                LIMIT 5
            """)

            for i, record in enumerate(result, 1):
                print(f"{i}. ({record['source']}) -[{record['relationship']} (æƒé‡:{record['weight']:.2f})]-> ({record['target']})")

            print("="*60)


def main():
    """ä¸»å‡½æ•°"""

    # ========== é…ç½®åŒºåŸŸ ==========
    NEO4J_URI = "bolt://localhost:7687"
    NEO4J_USER = "neo4j"
    NEO4J_PASSWORD = "jbh966225"

    JSON_FILE = "./extracted_data/graph_data.json"

    BATCH_SIZE = 1000
    CLEAR_DATABASE = True # å¦‚æœä½ ä¹‹å‰å·²ç»å¯¼å…¥äº†å®ä½“ï¼Œè¿™é‡Œè®¾ä¸º False ä»¥å…é‡æ–°å¯¼å®ä½“
    USE_APOC = False
    # ==============================

    print("\n" + "="*60)
    print("å¼€å§‹å¯¼å…¥æ•°æ®åˆ° Neo4j (ä¿®å¤ç‰ˆ)")
    print("="*60)

    try:
        importer = Neo4jImporter(
            uri=NEO4J_URI,
            user=NEO4J_USER,
            password=NEO4J_PASSWORD
        )
    except Exception as e:
        print(f"\nâœ— åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    try:
        # 1. åŠ è½½æ•°æ®
        print("\næ­¥éª¤ 1: åŠ è½½æ•°æ®")
        data = importer.load_json_data(JSON_FILE)
        entities = data['entities']
        triples = data['triples']

        # 2. å¯é€‰ï¼šæ¸…ç©ºæ•°æ®åº“
        if CLEAR_DATABASE:
            print("\næ­¥éª¤ 2: æ¸…ç©ºæ•°æ®åº“")
            importer.clear_database(confirm=True)

            # 3. åˆ›å»ºçº¦æŸå’Œç´¢å¼•
            print("\næ­¥éª¤ 3: åˆ›å»ºçº¦æŸå’Œç´¢å¼•")
            importer.create_constraints_and_indexes()

            # 4. å¯¼å…¥å®ä½“
            print("\næ­¥éª¤ 4: å¯¼å…¥å®ä½“")
            importer.import_entities(entities, batch_size=BATCH_SIZE)
        else:
            # å¦‚æœä¸æ¸…ç©ºæ•°æ®åº“ï¼Œå®ä½“åº”è¯¥å·²ç»å­˜åœ¨ï¼Œåªéœ€ç¡®ä¿ç´¢å¼•å­˜åœ¨
            print("\næ­¥éª¤ 2: æ£€æŸ¥/åˆ›å»ºç´¢å¼•")
            importer.create_constraints_and_indexes()

        # 5. å¯¼å…¥å…³ç³»
        print("\næ­¥éª¤ 5: å¯¼å…¥å…³ç³»")
        importer.import_relationships_without_apoc(triples, batch_size=BATCH_SIZE)

        # 6. éªŒè¯å¯¼å…¥
        print("\næ­¥éª¤ 6: éªŒè¯å¯¼å…¥")
        importer.verify_import()

        print("\n" + "="*60)
        print("âœ… å¯¼å…¥å®Œæˆï¼")
        print("="*60)

    except Exception as e:
        print(f"\nâœ— å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        importer.close()


if __name__ == "__main__":
    main()
